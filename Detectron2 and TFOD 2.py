# -*- coding: utf-8 -*-
"""Untitled18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1no0sp1mrB6mZjqd3fYlaBIWbyDt-UI4-

# Detectron2 and TFOD 2

#Assignment Questions

1. What types of tasks does Detectron2 support?

=> Detectron2 is a versatile object detection framework that supports various tasks, including:

Object detection (bounding box detection)
Instance segmentation (detecting and segmenting objects)
Keypoint detection (detecting and localizing keypoints on objects)


2. Why is data annotation important when training object detection models?

=> Data annotation is crucial for training object detection models as it provides the model with the necessary ground truth information. This information helps the model learn to recognize and localize objects accurately.


3. What does batch size refer to in the context of model training?

=> Batch size refers to the number of training samples processed in each iteration during training. A larger batch size can lead to faster training but may require more memory.


4. What is the purpose of pretrained weights in object detection models?


=> Pretrained weights are weights that have been learned on a large dataset (like ImageNet). Using pretrained weights can significantly improve the performance of object detection models, especially when training on smaller datasets.


5. How can you verify that Detectron2 was installed correctly?


You can verify the installation by running a simple script like:

=> Python code
import detectron2
print(detectron2.__version__)
Use code with caution.

If the version is printed correctly, then Detectron2 is installed.



6. What is TFOD2, and why is it widely used?


=> TFOD2 (TensorFlow Object Detection API) is a popular open-source framework for object detection. It is widely used due to its ease of use, flexibility, and integration with TensorFlow.


7. How does learning rate affect model training in Detectron2?

=> Learning rate determines the step size in the optimization process. A higher learning rate can lead to faster convergence but may also cause instability. A lower learning rate can lead to more stable training but may take longer to converge.


8. Why might Detectron2 use PyTorch as its backend framework?

=> PyTorch is a popular deep learning framework known for its flexibility and ease of use. It provides a dynamic computational graph that is well-suited for research and experimentation.


9. What types of pretrained models does TFOD2 support?


=> TFOD2 supports various pre-trained models, including SSD MobileNet V2 FPN, Faster R-CNN Inception V2 FPN, and Mask R-CNN Inception V2 FPN.


10. How can data path errors impact Detectron2?


=> Data path errors can prevent Detectron2 from accessing the training data correctly, leading to training failures.


11. What is Detectron2?


=> Detectron2 is a state-of-the-art object detection framework built on PyTorch.


12. What are TFRecord files, and why are they used in TFOD2?


=> TFRecord files are a file format used to store training data in a serialized format. They are efficient for reading and writing large datasets.


13. What evaluation metrics are typically used with Detectron2?


=> Common evaluation metrics used with Detectron2 include:

Mean Average Precision (mAP)
Precision
Recall


14. How do you perform inference with a trained Detectron2 model?


=> You can perform inference with a trained Detectron2 model by using the predictor object. The predictor object takes an image as input and returns the detected objects with their bounding boxes and class labels.


15. What does TFOD2 stand for, and what is it designed for?


=> TFOD2 stands for TensorFlow Object Detection API. It is designed for building and training object detection models using TensorFlow.


16. What does fine-tuning pretrained weights involve?


=> Fine-tuning involves training a pre-trained model on a new dataset with a smaller learning rate to adapt the model to the new task.


17. How is training started in TFOD2?


=> Training in TFOD2 is typically started by running a Python script that specifies the model configuration and training parameters.


18. What does COCO format represent, and why is it popular in Detectron2?


=> COCO format is a common format for object detection datasets. It includes information about object categories, bounding boxes, and segmentation masks. It is popular in Detectron2 due to its wide adoption and the availability of pre-trained models trained on the COCO dataset.


19. Why is evaluation curve plotting important in Detectron2?


=> Evaluation curve plotting helps visualize the model's performance during training and identify potential issues like overfitting or underfitting.



20. How do you configure data paths in TFOD2?


=> Data paths in TFOD2 are configured using the pipeline config file. This file specifies the location of the training data and validation data.



21. Can you run Detectron2 on a CPU?


=> Yes, Detectron2 can be run on a CPU, but GPU acceleration is highly recommended for faster training and inference.


22. Why are label maps used in TFOD2?

=> Label maps are used to map integer class labels to human-readable class names.


23. What makes TFOD2 popular for real-time detection tasks?


=> TFOD2 supports various efficient object detection models that can be deployed for real-time applications.



24. How does batch size impact GPU memory usage?


=> A larger batch size requires more GPU memory, so it's important to choose an appropriate batch size based on your available GPU memory.



25. What's the role of Intersection over Union (IoU) in model evaluation?


=> IoU is a metric used to measure the overlap between predicted bounding boxes and ground truth bounding boxes. It is used to evaluate the accuracy of object detection models.


26. What is Faster R-CNN, and does TFOD2 support it?


=> Faster R-CNN is a popular object detection model that uses a Region Proposal Network (RPN) to generate region proposals. TFOD2 supports Faster R-CNN.



27. How does Detectron2 use pretrained weights?


=> Detectron2 can use pretrained weights to initialize the model's parameters, which can improve the model's performance.



28. What file format is typically used to store training data in TFOD2?


=> TFOD2 typically uses TFRecord files to store training data.


29. What is the difference between semantic segmentation and instance segmentation?


=> Semantic segmentation assigns a class label to each pixel in an image. Instance segmentation not only assigns a class label to each pixel but also identifies individual instances of objects.


30. Can Detectron2 detect custom classes during inference?


=> Yes, Detectron2 can detect custom classes during inference by training the model on a dataset containing the custom classes.


31. Why is pipeline.config essential in TFOD2?


=> The pipeline config file is essential in TFOD2 as it defines all the parameters for training and inference, including the model architecture, hyperparameters, and data paths.



32. What type of models does TFOD2 support for object detection?


=> TFOD2 supports various object detection models, including SSD, Faster R-CNN, and Mask R-CNN.



33. What happens if the learning rate is too high during training?


=> If the learning rate is too high, the model may diverge and fail to converge.



34. What is COCO JSON format?


=> COCO JSON format is a file format used to store annotations for object detection datasets. It includes information about object categories, bounding boxes, and segmentation masks.



35. Why is TensorFlow Lite compatibility important in TFOD2?


=> TensorFlow Lite compatibility is important in TFOD2 as it allows deploying the trained models on mobile and embedded devices.
"""

# Practical

# 1. How do you install Detectron2 using pip and check the version of Detectron2?

# Install Detectron2
pip install detectron2

# Check the version
import detectron2
print(detectron2.__version__)

# 2. How do you perform inference with Detectron2 using an online image?
import cv2
from detectron2.config import get_cfg
from detectron2.engine import DefaultPredictor

# Load the model configuration and weights
cfg = get_cfg()
cfg.merge_from_file("path/to/model_config.yaml")
cfg.MODEL.WEIGHTS = "path/to/model_weights.pth"
cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set a threshold for detections

# Create a predictor
predictor = DefaultPredictor(cfg)

# Load the image from the web
img_url = "https://example.com/image.jpg"
img = cv2.imread(cv2.imdecode(np.frombuffer(requests.get(img_url).content, np.uint8), -1))

# Perform inference
outputs = predictor(img)

# Visualize the results
v = Visualizer(img[:, :, ::-1], MetadataCatalog.get("coco"))
v = v.draw_instance_predictions(outputs["instances"].to("cpu"))
cv2.imshow("Detectron2 Output", v.get_image()[:, :, ::-1])
cv2.waitKey(0)
cv2.destroyAllWindows()

# 3. How do you visualize evaluation metrics in Detectron2, such as training loss?

# Detectron2 provides tools for visualizing evaluation metrics like training loss. Here are two common approaches:

# 1. Using TensorBoard:

# Configure TensorBoard: In your training script, enable TensorBoard logging by setting the cfg.OUTPUT_DIR and cfg.SOLVER.LOG_ITERS parameters.
# Start TensorBoard: Run tensorboard --logdir output in your terminal, where output is the directory specified in your configuration.
# Visualize Metrics: Open TensorBoard in your web browser and navigate to the "Scalars" tab. You can view the training loss, validation loss, and other metrics over time.
# 2. Custom Visualization:

# Access Metrics: After training, you can access the training and validation metrics from the trainer object.
# Plot Metrics: Use libraries like Matplotlib or Plotly to plot the metrics over time. Here's a basic example using Matplotlib:



import matplotlib.pyplot as plt

# Assuming you have a list of training losses and validation losses
train_losses = [loss1, loss2, ...]
val_losses = [val_loss1, val_loss2, ...]

# Create a plot
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show() 1

# 3  How do you run inference with TFOD2 on an online image

# 1. Import Necessary Libraries:
import tensorflow as tf
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util
import numpy as np
import cv2
import requests

# 2 Load the Saved Model:

model_dir = 'path/to/your/saved_model'
model = tf.saved_model.load(model_dir)

# 3 Load the Label Map:
category_index = label_map_util.load_labelmap('path/to/label_map.pbtxt')

#  4 Download the Image:

img_url = 'https://example.com/image.jpg'
response = requests.get(img_url)
img_array = np.array(bytearray(response.content), dtype=np.uint8)
img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)

# 5  Preprocess the Image:

image_np = np.array(img)
input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)

#  6  Run Inference:
detections = model(input_tensor)

# 7  Visualize the Results:

num_detections = int(detections.pop('num_detections'))
detections = {key: value[0, :num_detections].numpy()
               for key, value in detections.items()}
detections['num_detections'] = num_detections

# visualization of the results of detection.
vis_util.visualize_boxes_and_labels_on_image_array(
    image_np,
    detections['detection_boxes'],
    detections['detection_classes'],
    detections['detection_scores'],
    category_index,
    instance_masks=detections.get('detection_masks'),
    use_normalized_coordinates=True,
    max_boxes_to_draw=200,
    min_score_thresh=.5,
    agnostic_mode=False)

plt.imshow(image_np)
plt.show()

# 5. How do you install TensorFlow Object Detection API in Jupyter Notebook?

!pip install tensorflow-object-detection-api

# 6. How can you load a pre-trained TensorFlow Object Detection model?

import tensorflow as tf
from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as vis_util

# Load the model
model_dir = "path/to/model_dir"
model = tf.saved_model.load(model_dir)

# Load the label map
category_index = label_map_util.load_labelmap("path/to/label_map.pbtxt")

# 7. How do you preprocess an image from the web for TFOD2 inference?

import numpy as np
import cv2
import requests

# Load the image from the web
img_url = "https://example.com/image.jpg"
img = cv2.imread(cv2.imdecode(np.frombuffer(requests.get(img_url).content, np.uint8), -1))

# Preprocess the image (resize, normalize, etc.)
image_np = np.array(img)
input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)

# 8. How do you visualize bounding boxes for detected objects in TFOD2 inference?

# Run inference
detections = model(input_tensor)

# Visualize the results
vis_util.visualize_boxes_and_labels_on_image_array(
    image_np,
    detections['detection_boxes'][0].numpy(),
    detections['detection_classes'][0].numpy().astype(np.int32),
    detections['detection_scores'][0].numpy(),
    category_index,
    use_normalized_coordinates=True,
    max_boxes_to_draw=200,
    min_score_thresh=.5,
    agnostic_mode=False)

plt.imshow(image_np)
plt.show()

# 9. How do you define custom training in TFOD2?

# To define custom training in TFOD2, you'll need to create a pipeline configuration file (pipeline.config). This file specifies the model architecture, training data, hyperparameters, and other settings for your custom object detection task.


model {
  ssd {
    num_classes: 90  # Adjust this to your number of classes
    ...
  }
}

train_config {
  batch_size: 24
  num_steps: 100000
  optimizer {
    rms_prop_optimizer {
      learning_rate {
        manual_step_decay_learning_rate {
          initial_learning_rate: 0.004
          ...
        }
      }
      momentum_optimizer_value: 0.9
      decay: 0.9
      epsilon: 1.0e-10
    }
  }
}

train_input_reader {
  label_map_path: "path/to/label_map.pbtxt"
  tf_record_input_reader {
    input_path: "path/to/train.record"
  }
}

# 10. How do you define classes for custom training in TFOD2?

# o define classes for custom training in TFOD2, you need to create a label map file. This file maps integer class IDs to human-readable class names. Here's how to create and use a label map:

# 1. Create a label_map.pbtxt file:

# This file should have the following format:

item {
  id: 1
  name: 'class1'
}
item {
  id: 2
  name: 'class2'
}
...
# Replace class1, class2, etc., with your actual class names. The id field should be an integer starting from 1.

# 2. Use the Label Map in the Pipeline Config:

# In your pipeline config file, reference the label map path:

train_input_reader {
  label_map_path: "path/to/label_map.pbtxt"
  ...
}

# 3. Update the Model's Number of Classes:

# In your model configuration, set the num_classes parameter to match the number of classes in your label map:

model {
  ssd {
    num_classes: 5  # Adjust this to your number of classes
    ...
  }
}

# 11. How do you resize an image before detecting objects?

# There are two primary methods to resize an image before detecting objects:

# Method 1: Using OpenCV

# Import the necessary library:

import cv2

# Read the image:

img = cv2.imread('path/to/image.jpg')

# Resize the image:

resized_img = cv2.resize(img, (new_width, new_height))

# Replace new_width and new_height with your desired dimensions.

# Method 2: Using TensorFlow

# Import necessary libraries:
import tensorflow as tf

# Read the image:

image = tf.io.read_file('path/to/image.jpg')
image = tf.image.decode_jpeg(image, channels=3)

# Resize the image:
resized_image = tf.image.resize(image, [new_height, new_width])

# 12. How can you apply a color filter (e.g., red filter) to an image?

# Apply a red filter
img[:, :, 0] = 255  # Set the red channel to maximum